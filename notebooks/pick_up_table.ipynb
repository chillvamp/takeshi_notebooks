{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Import the required libraries and initialize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from std_srvs.srv import Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "import rospy\n",
    "#import cv2\n",
    "import ros_numpy\n",
    "import numpy as np\n",
    "from tmc_tabletop_segmentator.srv import TabletopSegmentation\n",
    "from tmc_tabletop_segmentator.srv import TabletopSegmentationRequest\n",
    "from sensor_msgs.msg import Image\n",
    "from std_msgs.msg import String\n",
    "import tf\n",
    "import tf2_ros\n",
    "import geometry_msgs.msg\n",
    "from utils_notebooks import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ros_numpy\n",
    "import rospy\n",
    "import tf\n",
    "from gazebo_ros import gazebo_interface\n",
    "from sensor_msgs.msg import LaserScan, PointCloud2\n",
    "from geometry_msgs.msg import Pose, Quaternion ,TransformStamped\n",
    "import moveit_commander\n",
    "import moveit_msgs.msg\n",
    "\n",
    "import sys\n",
    "\n",
    "from utils_notebooks import *\n",
    "#from utils_task1 import *\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "ja"
   },
   "source": [
    "# REMEMBER TO RUN MOVEIT \n",
    "# roslaunch  hsrb_moveit_config  hsrb_demo_with_controller.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1-dev'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! roslaunch  hsrb_moveit_config  hsrb_demo_with_controller.launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bridge = CvBridge()\n",
    "###might take some time to load all those takeshi meshes in rviz\n",
    "\n",
    "head = moveit_commander.MoveGroupCommander('head')\n",
    "arm = moveit_commander.MoveGroupCommander('arm')\n",
    "whole_body = moveit_commander.MoveGroupCommander('whole_body_light')\n",
    "whole_body.set_workspace([-6.0, -6.0, 6.0, 6.0])#whole_body.go(wb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /home/oscar/Codes/catkin_mio_ws/src/hsrb_samples/hsrb_vision_samples/src/hsrb_vision_samples/execute_tabletop_segmentation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python /home/oscar/Codes/catkin_mio_ws/src/hsrb_samples/hsrb_vision_samples/src/hsrb_vision_samples/execute_tabletop_segmentation_backup.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rospy.init_node(\"recognition\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_2_np(wp_p):\n",
    "   \n",
    "    return np.asarray((wp_p.pose.position.x,wp_p.pose.position.y,wp_p.pose.position.z)) , np.asarray((wp_p.pose.orientation.w,wp_p.pose.orientation.x,wp_p.pose.orientation.y, wp_p.pose.orientation.z)) \n",
    "def np_2_pose(position,orientation):\n",
    "    wb_p= geometry_msgs.msg.PoseStamped()\n",
    "    \n",
    "    wb_p.pose.position.x= position[0]\n",
    "    wb_p.pose.position.y= position[1]\n",
    "    wb_p.pose.position.z= position[2]\n",
    "    wb_p.pose.orientation.w= orientation[0]\n",
    "    wb_p.pose.orientation.x= orientation[1]\n",
    "    wb_p.pose.orientation.y= orientation[2]\n",
    "    wb_p.pose.orientation.z= orientation[3]\n",
    "    return wb_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbd = RGBD()\n",
    "#a listener xtion rgbd listener class , (check utils for methods )\n",
    "# TF is one of the most powerfull underated Ros tools, I recomend to understand it and use it as often as possible.\n",
    "listener = tf.TransformListener()\n",
    "broadcaster= tf.TransformBroadcaster()\n",
    "tf_static_broadcaster= tf2_ros.StaticTransformBroadcaster()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_octo_client = rospy.ServiceProxy('/clear_octomap', Empty)\n",
    "\n",
    "clear_octo_client.wait_for_service(timeout=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= rgbd.get_h_image()\n",
    "points_data= rgbd.get_points()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_pca(lower=2000,higher=50000,reg_ly=0,reg_hy=1000): \n",
    "    image= rgbd.get_h_image()\n",
    "    points_data= rgbd.get_points()\n",
    "    values=image.reshape((-1,3))\n",
    "    values= np.float32(values)\n",
    "    criteria= (  cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER  ,1000,0.1)\n",
    "    k=6\n",
    "    _ , labels , cc =cv2.kmeans(values , k ,None,criteria,30,cv2.KMEANS_RANDOM_CENTERS)\n",
    "    cc=np.uint8(cc)\n",
    "    segmented_image= cc[labels.flatten()]\n",
    "    segmented_image=segmented_image.reshape(image.shape)\n",
    "    th3 = cv2.adaptiveThreshold(segmented_image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    im4=cv2.erode(th3,kernel,iterations=4)\n",
    "    plane_mask=points_data['z']\n",
    "    cv2_img=plane_mask.astype('uint8')\n",
    "    img=im4\n",
    "    _,contours, hierarchy = cv2.findContours(im4.astype('uint8'),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    i=0\n",
    "    cents=[]\n",
    "    points=[]\n",
    "    for i, contour in enumerate(contours):\n",
    "        \n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        if area > lower and area < higher :\n",
    "            M = cv2.moments(contour)\n",
    "            # calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            \n",
    "    \n",
    "            boundRect = cv2.boundingRect(contour)\n",
    "            #just for drawing rect, dont waste too much time on this\n",
    "\n",
    "            img=cv2.rectangle(img,(boundRect[0], boundRect[1]),(boundRect[0]+boundRect[2], boundRect[1]+boundRect[3]), (0,0,0), 2)\n",
    "            # calculate moments for each contour\n",
    "            if (cY > reg_ly and cY < reg_hy  ):\n",
    "                \n",
    "                cv2.circle(img, (cX, cY), 5, (255, 255, 255), -1)\n",
    "                cv2.putText(img, \"centroid_\"+str(i)+\"_\"+str(cX)+','+str(cY)    ,    (cX - 25, cY - 25)   ,cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                print ('cX,cY',cX,cY)\n",
    "                xyz=[]\n",
    "\n",
    "\n",
    "                for jy in range (boundRect[0], boundRect[0]+boundRect[2]):\n",
    "                    for ix in range(boundRect[1], boundRect[1]+boundRect[3]):\n",
    "                        aux=(np.asarray((points_data['x'][ix,jy],points_data['y'][ix,jy],points_data['z'][ix,jy])))\n",
    "                        if np.isnan(aux[0]) or np.isnan(aux[1]) or np.isnan(aux[2]):\n",
    "                            'reject point'\n",
    "                        else:\n",
    "                            xyz.append(aux)\n",
    "\n",
    "                xyz=np.asarray(xyz)\n",
    "                cent=xyz.mean(axis=0)\n",
    "                cents.append(cent)\n",
    "                print (cent)\n",
    "                points.append(xyz)\n",
    "            else:\n",
    "                print ('cent out of region... rejected')\n",
    "            \n",
    "    cents=np.asarray(cents)\n",
    "    ### returns centroids found and a group of 3d coordinates that conform the centroid\n",
    "    return(cents,np.asarray(points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cX,cY', 190, 445)\n",
      "[-0.3157453   0.40200213  1.1552731 ]\n",
      "('cX,cY', 312, 410)\n",
      "[-0.01709246  0.39382246  1.329498  ]\n",
      "('cX,cY', 521, 376)\n",
      "[0.52530545 0.16792011 1.5207028 ]\n",
      "('cX,cY', 570, 413)\n",
      "[0.58895457 0.40709126 1.2982366 ]\n",
      "('cX,cY', 132, 119)\n",
      "[-0.8250307 -0.6395786  2.7912288]\n",
      "('cX,cY', 459, 201)\n",
      "[ 0.36349332 -0.10311315  1.4257983 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-0.3157453 ,  0.40200213,  1.1552731 ],\n",
       "        [-0.01709246,  0.39382246,  1.329498  ],\n",
       "        [ 0.52530545,  0.16792011,  1.5207028 ],\n",
       "        [ 0.58895457,  0.40709126,  1.2982366 ],\n",
       "        [-0.8250307 , -0.6395786 ,  2.7912288 ],\n",
       "        [ 0.36349332, -0.10311315,  1.4257983 ]], dtype=float32),\n",
       " array([array([[-0.2574901 ,  0.14972764,  0.57443887],\n",
       "        [-0.25767463,  0.15087187,  0.57485056],\n",
       "        [-0.25785947,  0.15201776,  0.5752629 ],\n",
       "        ...,\n",
       "        [-0.13660249,  0.49531436,  1.1561841 ],\n",
       "        [-0.13635086,  0.49648365,  1.1540543 ],\n",
       "        [-0.13610014,  0.49764863,  1.1519324 ]], dtype=float32),\n",
       "        array([[-0.10035053,  0.26995707,  1.5671154 ],\n",
       "        [-0.10010013,  0.27210316,  1.5632051 ],\n",
       "        [-0.09985097,  0.2742386 ,  1.5593143 ],\n",
       "        ...,\n",
       "        [ 0.04485995,  0.49554595,  1.1567247 ],\n",
       "        [ 0.04477727,  0.49671534,  1.1545929 ],\n",
       "        [ 0.04469491,  0.4978805 ,  1.152469  ]], dtype=float32),\n",
       "        array([[ 0.1364385 , -0.26303095,  1.5595701 ],\n",
       "        [ 0.13657609, -0.26048017,  1.5611427 ],\n",
       "        [ 0.13671392, -0.2579242 ,  1.5627183 ],\n",
       "        ...,\n",
       "        [ 0.6677092 ,  0.4963409 ,  1.1585803 ],\n",
       "        [ 0.6664766 ,  0.49751073,  1.1564417 ],\n",
       "        [ 0.66524863,  0.4986762 ,  1.154311  ]], dtype=float32),\n",
       "        array([[0.5624784 , 0.36276698, 1.4014755 ],\n",
       "        [0.5612229 , 0.36447957, 1.3983473 ],\n",
       "        [0.559973  , 0.3661846 , 1.395233  ],\n",
       "        ...,\n",
       "        [0.62539643, 0.453719  , 1.2360392 ],\n",
       "        [0.624165  , 0.45505077, 1.2336053 ],\n",
       "        [0.62293833, 0.4563773 , 1.2311809 ]], dtype=float32),\n",
       "        array([[-2.017068  , -1.0700877 ,  3.49993   ],\n",
       "        [-2.0181508 , -1.0643455 ,  3.5018086 ],\n",
       "        [-2.0192347 , -1.0585972 ,  3.5036895 ],\n",
       "        ...,\n",
       "        [ 0.04178231, -0.17656395,  1.4944122 ],\n",
       "        [ 0.04182268, -0.1740363 ,  1.495856  ],\n",
       "        [ 0.04186312, -0.17150375,  1.4973027 ]], dtype=float32),\n",
       "        array([[ 2.7705517e-01, -2.2668150e-01,  1.6427230e+00],\n",
       "        [ 2.7584216e-01, -2.2273885e-01,  1.6355307e+00],\n",
       "        [ 2.7463973e-01, -2.1883057e-01,  1.6284012e+00],\n",
       "        ...,\n",
       "        [ 7.0741659e-01, -9.3821827e-03,  2.0805280e+00],\n",
       "        [ 7.0507509e-01, -5.6106769e-03,  2.0736415e+00],\n",
       "        [ 7.0274901e-01, -1.8640558e-03,  2.0668006e+00]], dtype=float32)],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize ROS publisher\n",
    "pub = rospy.Publisher('goal', PoseStamped, queue_size=10)\n",
    "\n",
    "# wait to establish connection between the navigation interface\n",
    "# move_base and navigation_log_recorder node\n",
    "\n",
    "def move_base(x,y,th, ref='map'):\n",
    "    # input goal pose\n",
    "    goal_x = x\n",
    "    goal_y = y\n",
    "    goal_yaw =th\n",
    "\n",
    "    # fill ROS message\n",
    "    goal = PoseStamped()\n",
    "    goal.header.stamp = rospy.Time.now()\n",
    "    goal.header.frame_id = ref\n",
    "    goal.pose.position = Point(goal_x, goal_y, 0)\n",
    "    quat = tf.transformations.quaternion_from_euler(0, 0, goal_yaw)\n",
    "    goal.pose.orientation = Quaternion(*quat)\n",
    "    # publish ROS message\n",
    "    pub.publish(goal)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-669a3c1ab277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_named_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'go'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arm' is not defined"
     ]
    }
   ],
   "source": [
    "arm.set_named_target('go')\n",
    "arm.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_client = rospy.ServiceProxy('/tabletop_segmentator_node/execute', TabletopSegmentation)\n",
    "service_client.wait_for_service(timeout=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_base(1.5,1.13,.5*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "head_val=head.get_current_joint_values()\n",
    "#head_val[0]=np.deg2rad(0)\n",
    "head_val[1]=np.deg2rad(-45)\n",
    "\n",
    "head.go(head_val)\n",
    "#If head didnt move, MOVE IT isnt running  properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgbd.get_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run this in terminal (TABLETOP SEGMENTATION )\n",
    "#  rviz -d `rospack find hsrb_vision_samples`/config/tabletop.rvizro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position: \n",
      "  x: -0.00537264253944\n",
      "  y: 0.206462979317\n",
      "  z: 0.851000010967\n",
      "orientation: \n",
      "  x: 0.860281050205\n",
      "  y: 0.000278744439129\n",
      "  z: 0.000470359576866\n",
      "  w: 0.509819686413\n",
      "position: \n",
      "  x: 0.215436935425\n",
      "  y: 0.0186180062592\n",
      "  z: 0.983000040054\n",
      "orientation: \n",
      "  x: 0.95496994257\n",
      "  y: 0.0412563197315\n",
      "  z: -0.159782290459\n",
      "  w: -0.246576413512\n",
      "[INFO] [1634828041.788245, 205.227000]: Number of detected objects=2\n",
      "[INFO] [1634828041.791949, 205.233000]: Number of detected planes=2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#define a tabletop segmentation request.\n",
    "# Play with these parameters\n",
    "\n",
    "\n",
    "req = TabletopSegmentationRequest()\n",
    "req.crop_enabled = True  # limit the processing area\n",
    "req.crop_x_max = 0.7     # X coordinate maximum value in the area [m]\n",
    "req.crop_x_min = -0.7    # X coordinate minimum value in the area [m]\n",
    "req.crop_y_max = 1.0     # Y coordinate maximum value in the area [m]\n",
    "req.crop_y_min = -1.0    # Y coordinate minimum value in the area [m]\n",
    "req.crop_z_max = 1.1     # Z coordinate maximum value in the area [m]\n",
    "req.crop_z_min = 0.0     # Z coordinate minimum value in the area [m]\n",
    "req.cluster_z_max = 1.0  # maximum height value of cluster on table [m]\n",
    "req.cluster_z_min = 0.0  # minimum height value of cluster on table [m]\n",
    "req.remove_bg = True    # remove the background of the segment image\n",
    "\n",
    "res = service_client(req)\n",
    "for i in range (len(res.table_array.tables)):\n",
    "    print (res.table_array.tables[i].pose)\n",
    "\n",
    "rospy.loginfo('Number of detected objects={0}'.format(\n",
    "    len(   res.segmented_objects_array.table_objects_array)))\n",
    "rospy.loginfo('Number of detected planes={0}'.format(\n",
    "    len(res.table_array.tables)))\n",
    "#(trans,rot)=tf_listener.lookupTransform('hand_palm_link', 'map', rospy.Time(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Plane', 0, 'has', 3, 'objects')\n",
      "(0, 0)\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "('Plane', 1, 'has', 3, 'objects')\n",
      "(1, 0)\n",
      "(1, 1)\n",
      "(1, 2)\n",
      "[array([ 0.20497664, -0.09361606,  0.98184101]), array([0.0675759 , 0.2400879 , 0.71437308]), array([0.21690061, 0.25146039, 0.67766818]), array([-0.15521452,  0.23096908,  0.76600203]), array([-0.24216753,  0.26763469,  0.75646812]), array([-0.37058958,  0.32604629,  0.84662878])]\n"
     ]
    }
   ],
   "source": [
    "objs_depth_centroids=[]\n",
    "for i in range (len(res.segmented_objects_array.table_objects_array\t)):\n",
    "    print ( 'Plane',i,'has', len(res.segmented_objects_array.table_objects_array[i].depth_image_array), 'objects')\n",
    "    for j in range (len(res.segmented_objects_array.table_objects_array[i].points_array)):\n",
    "        cv2_img_depth = bridge.imgmsg_to_cv2(res.segmented_objects_array.table_objects_array[i].depth_image_array[0] )\n",
    "        cv2_img = bridge.imgmsg_to_cv2(res.segmented_objects_array.table_objects_array[i].rgb_image_array[0] )\n",
    "        pc= ros_numpy.numpify (res.segmented_objects_array.table_objects_array[i].points_array[j])\n",
    "        points=np.zeros((pc.shape[0],3))\n",
    "        points[:,0]=pc['x']\n",
    "        points[:,1]=pc['y']\n",
    "        points[:,2]=pc['z']\n",
    "        objs_depth_centroids.append(np.mean(points,axis=0))\n",
    "        print(i,j)\n",
    "print objs_depth_centroids\n",
    "\n",
    "#lets publish a tf to this centroids ( lot of false positives) !!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.981841007975483)\n",
      "(1, 0.7143730786222845)\n",
      "(2, 0.6776681784283245)\n",
      "(3, 0.7660020254737702)\n",
      "(4, 0.7564681207164675)\n",
      "(5, 0.8466287801851464)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(objs_depth_centroids)):\n",
    "    #Table is a plane at z=.8 So we consider false positives all the centroids outside the region on axis z ( .79 , .9)\n",
    "    if objs_depth_centroids[i][2] > 0 and objs_depth_centroids[i][2] <44.9: \n",
    "        static_transformStamped = geometry_msgs.msg.TransformStamped()\n",
    "        broadcaster.sendTransform((objs_depth_centroids[i]),(0,0,0,1), rospy.Time.now(), 'Closest_Object'+str(i),\"head_rgbd_sensor_link\")\n",
    "        print (i,objs_depth_centroids[i][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_tf_publish(cents):\n",
    "    trans , rot = listener.lookupTransform('/map', '/head_rgbd_sensor_gazebo_frame', rospy.Time(0))\n",
    "    for  i ,cent  in enumerate(cents):\n",
    "        x,y,z=cent\n",
    "        if np.isnan(x) or np.isnan(y) or np.isnan(z):\n",
    "            print('nan')\n",
    "        else:\n",
    "            broadcaster.sendTransform((x,y,z),rot, rospy.Time.now(), 'Object'+str(i),\"head_rgbd_sensor_link\")\n",
    "            rospy.sleep(.2)\n",
    "            xyz_map,cent_quat= listener.lookupTransform('/map', 'Object'+str(i),rospy.Time(0))\n",
    "            map_euler=tf.transformations.euler_from_quaternion(cent_quat)\n",
    "            rospy.sleep(.2)\n",
    "            static_transformStamped = TransformStamped()\n",
    "            \n",
    "\n",
    "            ##FIXING TF TO MAP ( ODOM REALLY)    \n",
    "            #tf_broadcaster1.sendTransform( (xyz[0],xyz[1],xyz[2]),tf.transformations.quaternion_from_euler(0, 0, 0), rospy.Time.now(), \"obj\"+str(ind), \"head_rgbd_sensor_link\")\n",
    "            static_transformStamped.header.stamp = rospy.Time.now()\n",
    "            static_transformStamped.header.frame_id = \"map\"\n",
    "            \n",
    "            static_transformStamped.transform.translation.x = float(xyz_map[0])\n",
    "            static_transformStamped.transform.translation.y = float(xyz_map[1])\n",
    "            static_transformStamped.transform.translation.z = float(xyz_map[2])\n",
    "            #quat = tf.transformations.quaternion_from_euler(-euler[0],0,1.5)\n",
    "            static_transformStamped.transform.rotation.x = 0#-quat[0]#trans.transform.rotation.x\n",
    "            static_transformStamped.transform.rotation.y = 0#-quat[1]#trans.transform.rotation.y\n",
    "            static_transformStamped.transform.rotation.z = 0#-quat[2]#trans.transform.rotation.z\n",
    "            static_transformStamped.transform.rotation.w = 1#-quat[3]#trans.transform.rotation.w\n",
    "            if xyz_map[2] > .7 and xyz_map[2] < .85:\n",
    "                static_transformStamped.child_frame_id = \"Object_\"+str(i)+\"_Table_real_lab\"\n",
    "                tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "                print xyz_map[2]\n",
    "            \n",
    "            \n",
    "            if xyz_map[2] > .4 and xyz_map[2] < .46:   #table 1 \n",
    "                static_transformStamped.child_frame_id = \"Object_\"+str(i)+\"_Table_1\"\n",
    "                tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "                print xyz_map[2]\n",
    "            if  xyz_map[2] < .15:   #table 1 \n",
    "                static_transformStamped.child_frame_id = \"Object_\"+str(i)+\"_Floor\"\n",
    "                tf_static_broadcaster.sendTransform(static_transformStamped)\n",
    "                print xyz_map[2]\n",
    "    return True\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0508877271807\n",
      "0.0310569051248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_tf_publish(objs_depth_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cX,cY', 224, 443)\n",
      "[-0.25287107  0.39424276  1.1514323 ]\n",
      "('cX,cY', 359, 409)\n",
      "[0.10185773 0.39226657 1.3329693 ]\n",
      "('cX,cY', 518, 411)\n",
      "[0.48800257 0.38187936 1.3424295 ]\n",
      "('cX,cY', 599, 284)\n",
      "[0.8568816  0.12043008 1.7647218 ]\n",
      "('cX,cY', 157, 121)\n",
      "[-0.68328416 -0.63356704  2.7834322 ]\n",
      "('cX,cY', 515, 206)\n",
      "[ 0.49230784 -0.08857142  1.3920059 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.25287107,  0.39424276,  1.1514323 ],\n",
       "       [ 0.10185773,  0.39226657,  1.3329693 ],\n",
       "       [ 0.48800257,  0.38187936,  1.3424295 ],\n",
       "       [ 0.8568816 ,  0.12043008,  1.7647218 ],\n",
       "       [-0.68328416, -0.63356704,  2.7834322 ],\n",
       "       [ 0.49230784, -0.08857142,  1.3920059 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids,_=seg_pca()\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkout your rviz. You should be able to see a tf marker on the centroids published above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets add some working surfaces of the collision world scene in moveit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_object(name, size, pose, orientation):\n",
    "    p = PoseStamped()\n",
    "    p.header.frame_id = \"odom\"       # \"head_rgbd_sensor_link\"\n",
    "    \n",
    "    p.pose.position.x = pose[0]\n",
    "    p.pose.position.y = pose[1]\n",
    "    p.pose.position.z = pose[2]\n",
    "\n",
    "    p.pose.orientation.x = orientation[0] * np.pi\n",
    "    p.pose.orientation.w = orientation[1] * np.pi\n",
    "\n",
    "    scene.add_box(name, p, size)\n",
    "\n",
    "\n",
    "def publish_scene():\n",
    "    add_object(\"shelf\", [1.5, 0.04, 0.4], [2.5, 4.7, 0.78], [0.5, 0.5])\n",
    "    add_object(\"shelf1\", [1.5, 0.04, 0.4], [2.5, 4.7, 0.49], [0.5, 0.5])\n",
    "    add_object(\"shelf2\", [1.5, 0.04, 0.4], [2.5, 4.7, 0.18], [0.5, 0.5])\n",
    "    add_object(\"shelf_wall\", [1, 1, 0.04], [2.5, 4.9, 0.5], [0.5, 0.5])\n",
    "    add_object(\"shelf_wall1\", [.04, 1, 0.4], [2.7, 4.9, 0.5], [0.5, 0.5])\n",
    "    add_object(\"shelf_wall2\", [.04, 1, 0.4], [1.8, 4.9, 0.5], [0.5, 0.5])\n",
    "    \n",
    "    add_object(\"table_big\", [1.7, 0.13, 0.7], [0.95, 1.9, 0.34], [0.5, 0.5])\n",
    "    add_object(\"table_small\", [0.5, 0.01, 0.4], [0.1, 1.9, 0.61], [0.5, 0.5])\n",
    "    add_object(\"table_tray\", [0.65, 0.01, 0.7], [1.8, -0.65, 0.4], [0.5, 0.5])    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = moveit_commander.PlanningSceneInterface()\n",
    "scene_pub = rospy.Publisher('planning_scene',\n",
    "                                         moveit_msgs.msg.PlanningScene,\n",
    "                                         queue_size=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publish_scene()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## robot to neutral pose\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_body.set_workspace((-1,-1,5,5))\n",
    "scene.remove_world_object()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6079908898371214, 1.64596279379822, 0.03105690512478521]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## we already have a object pose belief. Let's take gripper to it\n",
    "xyz_map,quat_map= listener.lookupTransform(  '/odom','Object_3_Floor',rospy.Time(0))\n",
    "xyz_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "header: \n",
       "  seq: 0\n",
       "  stamp: \n",
       "    secs: 670\n",
       "    nsecs:  86000000\n",
       "  frame_id: \"odom\"\n",
       "pose: \n",
       "  position: \n",
       "    x: 2.21194282415\n",
       "    y: 0.281467155386\n",
       "    z: 0.672799843287\n",
       "  orientation: \n",
       "    x: -0.608074972196\n",
       "    y: -0.362366843071\n",
       "    z: -0.606533728316\n",
       "    w: 0.362010960671"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb_p=whole_body.get_current_pose()\n",
    "wb_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_p=whole_body.get_current_pose()\n",
    "pose,quat=pose_2_np(wb_p)\n",
    "tf.transformations.euler_from_quaternion(quat),pose\n",
    "wb_t=wb_p\n",
    "wb_t.pose.position.x= xyz_map[0]\n",
    "wb_t.pose.position.y= xyz_map[1]\n",
    "wb_t.pose.position.z=.8\n",
    "wb_t.pose.orientation.w = 0.433\n",
    "wb_t.pose.orientation.x = -0.589\n",
    "wb_t.pose.orientation.y =  -0.429\n",
    "wb_t.pose.orientation.z =  -0.529\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scene.remove_world_object()\n",
    "\n",
    "whole_body.set_pose_target(wb_t)\n",
    "whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_octo_client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1634575330.634545]: Inbound TCP/IP connection failed: connection from sender terminated before handshake header received. 0 bytes were received. Please check sender for additional details.\n",
      "[WARN] [1634575330.675954]: Inbound TCP/IP connection failed: connection from sender terminated before handshake header received. 0 bytes were received. Please check sender for additional details.\n",
      "[WARN] [1634575330.804141]: Inbound TCP/IP connection failed: connection from sender terminated before handshake header received. 0 bytes were received. Please check sender for additional details.\n",
      "[WARN] [1634575330.838197]: Inbound TCP/IP connection failed: connection from sender terminated before handshake header received. 0 bytes were received. Please check sender for additional details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scene.remove_world_object()\n",
    "\n",
    "whole_body.set_pose_target(wb_t)\n",
    "whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.set_named_target('go')\n",
    "arm.go()\n",
    "\n",
    "head.set_named_target('neutral')\n",
    "head.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "header: \n",
       "  seq: 0\n",
       "  stamp: \n",
       "    secs: 1634576089\n",
       "    nsecs: 686543941\n",
       "  frame_id: \"odom\"\n",
       "pose: \n",
       "  position: \n",
       "    x: 0.26616484078\n",
       "    y: -0.104967105746\n",
       "    z: 0.785636180361\n",
       "  orientation: \n",
       "    x: 0.55844119682\n",
       "    y: -0.476828467316\n",
       "    z: 0.461132203878\n",
       "    w: 0.498131642237"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arm.get_current_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_p=whole_body.get_current_pose()\n",
    "pose,quat=pose_2_np(wb_p)\n",
    "tf.transformations.euler_from_quaternion(quat),pose\n",
    "wb_t=wb_p\n",
    "#wb_t.pose.position.x= xyz_map[0]\n",
    "#wb_t.pose.position.y= xyz_map[1]\n",
    "#wb_t.pose.position.z=.8\n",
    "wb_t.pose.orientation.w = 0.55\n",
    "wb_t.pose.orientation.x = -0.47\n",
    "wb_t.pose.orientation.y =  0.46\n",
    "wb_t.pose.orientation.z =  .5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] [1634576329.728657]: Inbound TCP/IP connection failed: connection from sender terminated before handshake header received. 0 bytes were received. Please check sender for additional details.\n"
     ]
    }
   ],
   "source": [
    "whole_body.set_pose_target(wb_t)\n",
    "whole_body.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sort_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-75dc45a4de93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msort_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sort_list' is not defined"
     ]
    }
   ],
   "source": [
    "sort_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.20497664, -0.09361606,  0.98184101],\n",
       "        [-0.37058958,  0.32604629,  0.84662878],\n",
       "        [-0.24216753,  0.26763469,  0.75646812],\n",
       "        [-0.15521452,  0.23096908,  0.76600203],\n",
       "        [ 0.0675759 ,  0.2400879 ,  0.71437308],\n",
       "        [ 0.21690061,  0.25146039,  0.67766818]]),\n",
       " array([[ 0.20497664, -0.09361606,  0.98184101],\n",
       "        [ 0.0675759 ,  0.2400879 ,  0.71437308],\n",
       "        [ 0.21690061,  0.25146039,  0.67766818],\n",
       "        [-0.15521452,  0.23096908,  0.76600203],\n",
       "        [-0.24216753,  0.26763469,  0.75646812],\n",
       "        [-0.37058958,  0.32604629,  0.84662878]]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cents= np.asarray(objs_depth_centroids)\n",
    "norms= np.linalg.norm(cents,axis=1)\n",
    "cents[np.argsort(-norms)], cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 5, 4, 3, 1, 2]),\n",
       " array([1.00736843, 0.75666214, 0.75466043, 0.81498305, 0.83816315,\n",
       "        0.98001179]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(-norms), norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f53d08756c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    }
   ],
   "source": [
    "np.concatenate((cents,cents.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'linalg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c7ff838a6093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'linalg'"
     ]
    }
   ],
   "source": [
    "cents.linalg.norm(axis=1).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21690061,  0.25146039,  0.67766818],\n",
       "       [ 0.0675759 ,  0.2400879 ,  0.71437308],\n",
       "       [-0.24216753,  0.26763469,  0.75646812],\n",
       "       [-0.15521452,  0.23096908,  0.76600203],\n",
       "       [-0.37058958,  0.32604629,  0.84662878],\n",
       "       [ 0.20497664, -0.09361606,  0.98184101]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/ros/melodic/lib/python2.7/dist-packages/cv2.so'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1-dev'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  },
  "nbTranslate": {
   "displayLangs": [
    "ja"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "ja",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
